{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 6564,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.09142857142857143,
      "grad_norm": 0.13246802985668182,
      "learning_rate": 1.9393662400975016e-05,
      "loss": 0.7575666046142578,
      "step": 200
    },
    {
      "epoch": 0.18285714285714286,
      "grad_norm": 0.043377961963415146,
      "learning_rate": 1.8784277879341867e-05,
      "loss": 0.008604106307029725,
      "step": 400
    },
    {
      "epoch": 0.2742857142857143,
      "grad_norm": 0.02229178696870804,
      "learning_rate": 1.8174893357708717e-05,
      "loss": 0.0032879805564880373,
      "step": 600
    },
    {
      "epoch": 0.3657142857142857,
      "grad_norm": 0.014376114122569561,
      "learning_rate": 1.7565508836075565e-05,
      "loss": 0.0017895419895648957,
      "step": 800
    },
    {
      "epoch": 0.45714285714285713,
      "grad_norm": 0.009130197577178478,
      "learning_rate": 1.6956124314442416e-05,
      "loss": 0.0011342231929302215,
      "step": 1000
    },
    {
      "epoch": 0.5485714285714286,
      "grad_norm": 0.008712055161595345,
      "learning_rate": 1.6346739792809263e-05,
      "loss": 0.0007893721759319306,
      "step": 1200
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.0047711716033518314,
      "learning_rate": 1.5737355271176114e-05,
      "loss": 0.0005815992131829262,
      "step": 1400
    },
    {
      "epoch": 0.7314285714285714,
      "grad_norm": 0.0036808745935559273,
      "learning_rate": 1.5127970749542961e-05,
      "loss": 0.00044868968427181244,
      "step": 1600
    },
    {
      "epoch": 0.8228571428571428,
      "grad_norm": 0.0030047136824578047,
      "learning_rate": 1.4518586227909812e-05,
      "loss": 0.0003510700538754463,
      "step": 1800
    },
    {
      "epoch": 0.9142857142857143,
      "grad_norm": 0.0030071402434259653,
      "learning_rate": 1.3909201706276663e-05,
      "loss": 0.0002829070948064327,
      "step": 2000
    },
    {
      "epoch": 1.0054857142857143,
      "grad_norm": 0.0027329500298947096,
      "learning_rate": 1.329981718464351e-05,
      "loss": 0.0002342434972524643,
      "step": 2200
    },
    {
      "epoch": 1.0969142857142857,
      "grad_norm": 0.00218189531005919,
      "learning_rate": 1.2690432663010361e-05,
      "loss": 0.0001954777166247368,
      "step": 2400
    },
    {
      "epoch": 1.1883428571428571,
      "grad_norm": 0.001714480808004737,
      "learning_rate": 1.208104814137721e-05,
      "loss": 0.00016658775508403777,
      "step": 2600
    },
    {
      "epoch": 1.2797714285714286,
      "grad_norm": 0.001299507450312376,
      "learning_rate": 1.1471663619744061e-05,
      "loss": 0.00014589943923056124,
      "step": 2800
    },
    {
      "epoch": 1.3712,
      "grad_norm": 0.001328520243987441,
      "learning_rate": 1.0862279098110908e-05,
      "loss": 0.00012505817227065563,
      "step": 3000
    },
    {
      "epoch": 1.4626285714285714,
      "grad_norm": 0.0009717505890876055,
      "learning_rate": 1.0252894576477759e-05,
      "loss": 0.00010889656841754914,
      "step": 3200
    },
    {
      "epoch": 1.5540571428571428,
      "grad_norm": 0.0010442289058119059,
      "learning_rate": 9.643510054844608e-06,
      "loss": 9.797429665923119e-05,
      "step": 3400
    },
    {
      "epoch": 1.6454857142857144,
      "grad_norm": 0.000917791563551873,
      "learning_rate": 9.034125533211457e-06,
      "loss": 8.693367242813111e-05,
      "step": 3600
    },
    {
      "epoch": 1.7369142857142856,
      "grad_norm": 0.0011015264317393303,
      "learning_rate": 8.424741011578306e-06,
      "loss": 7.82531313598156e-05,
      "step": 3800
    },
    {
      "epoch": 1.8283428571428573,
      "grad_norm": 0.0008109147311188281,
      "learning_rate": 7.815356489945156e-06,
      "loss": 7.032104302197695e-05,
      "step": 4000
    },
    {
      "epoch": 1.9197714285714285,
      "grad_norm": 0.0007275599637068808,
      "learning_rate": 7.2059719683120055e-06,
      "loss": 6.401761900633574e-05,
      "step": 4200
    },
    {
      "epoch": 2.0109714285714286,
      "grad_norm": 0.0006469501531682909,
      "learning_rate": 6.596587446678855e-06,
      "loss": 5.782340187579393e-05,
      "step": 4400
    },
    {
      "epoch": 2.1024,
      "grad_norm": 0.0006788891623727977,
      "learning_rate": 5.987202925045705e-06,
      "loss": 5.408733151853085e-05,
      "step": 4600
    },
    {
      "epoch": 2.1938285714285715,
      "grad_norm": 0.0005889906897209585,
      "learning_rate": 5.377818403412554e-06,
      "loss": 4.96895145624876e-05,
      "step": 4800
    },
    {
      "epoch": 2.2852571428571427,
      "grad_norm": 0.0005867764702998102,
      "learning_rate": 4.768433881779403e-06,
      "loss": 4.591753240674734e-05,
      "step": 5000
    },
    {
      "epoch": 2.3766857142857143,
      "grad_norm": 0.0004830768157262355,
      "learning_rate": 4.159049360146253e-06,
      "loss": 4.3213102035224434e-05,
      "step": 5200
    },
    {
      "epoch": 2.468114285714286,
      "grad_norm": 0.0005854596965946257,
      "learning_rate": 3.5496648385131023e-06,
      "loss": 4.0526269003748894e-05,
      "step": 5400
    },
    {
      "epoch": 2.559542857142857,
      "grad_norm": 0.00042343823588453233,
      "learning_rate": 2.9402803168799514e-06,
      "loss": 3.838371019810438e-05,
      "step": 5600
    },
    {
      "epoch": 2.6509714285714283,
      "grad_norm": 0.000493766856379807,
      "learning_rate": 2.330895795246801e-06,
      "loss": 3.695200895890594e-05,
      "step": 5800
    },
    {
      "epoch": 2.7424,
      "grad_norm": 0.0004802820330951363,
      "learning_rate": 1.7215112736136503e-06,
      "loss": 3.488568356260657e-05,
      "step": 6000
    },
    {
      "epoch": 2.8338285714285716,
      "grad_norm": 0.00046848031342960894,
      "learning_rate": 1.1121267519804998e-06,
      "loss": 3.452287986874581e-05,
      "step": 6200
    },
    {
      "epoch": 2.925257142857143,
      "grad_norm": 0.0003493616823107004,
      "learning_rate": 5.027422303473492e-07,
      "loss": 3.344986820593476e-05,
      "step": 6400
    }
  ],
  "logging_steps": 200,
  "max_steps": 6564,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 520973485066368.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
